{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "created-datetime": "2022-08-09T12:25:33.652Z",
    "deps": [],
    "executions": 6,
    "id": "f4db09a0-bae1-40da-bb8a-885e1e83486e",
    "tags": []
   },
   "source": [
    "# Meta Analysis Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deps": [],
    "tags": []
   },
   "source": [
    "## Analysis Utilities\n",
    "The following functions are built to aid the development of helpful visualizations. These functions load the metadata.json (meta-data) file associated with the data analysis. \n",
    "\n",
    "- *getData* will load the metadata JSON file. \n",
    "- *getCellData* will load the different cell versions into a dataframe. Each cell version is labeled with a commit_id and time stamp. \n",
    "- *getNotebookData* will load the metrics generated by Cynosure for each notebook version. Again, each notebook version is labeled with a commit_id and a time stamp. \n",
    "- *convertToDate* and convertUnixTSToDate handle the conversion of different time-stamps into human-readable Python DateTime. \n",
    "- *createDataFrame* creates the data frames associated with cells versions and notebook versions. This function also calculates the number of items in columns that contain lists of items like 'vars' and 'tags'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "created-datetime": "2022-08-09T12:25:33.712Z",
    "executions": 3,
    "id": "a11913b9-bcd1-4e8b-8eae-41bf989e9123"
   },
   "outputs": [],
   "source": [
    "from enum import unique\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from dateutil import parser\n",
    "import numpy as np\n",
    "import altair as alt\n",
    "from itables import init_notebook_mode\n",
    "init_notebook_mode(all_interactive=True)\n",
    "\n",
    "def getData():\n",
    "    with open('meta-data.json') as fp:\n",
    "        data = json.load(fp)\n",
    "    \n",
    "    return data\n",
    "  \n",
    "def getCellData(data): \n",
    "    vers = []\n",
    "    versions = data['commits'].keys()\n",
    "    for version in versions:\n",
    "        notebooks = data[\"commits\"][version]['notebooks']\n",
    "        for notebook in notebooks:\n",
    "            cells = notebook['contents']['cells']\n",
    "            for i, cell in enumerate(cells):\n",
    "                info = dict(cell)\n",
    "\n",
    "                info.pop('metadata')\n",
    "                info.update(cell['metadata'])\n",
    "                \n",
    "                info['cell_index'] = chr(i + 97)\n",
    "                info['notebook'] = notebook['name']\n",
    "                info['commit_id'] = version\n",
    "                \n",
    "                info['time'] = data['commits'][version]['time']\n",
    "                vers.append(info)\n",
    "    \n",
    "    return vers\n",
    "\n",
    "def getNotebookData(data):\n",
    "    analysis = []\n",
    "    versions = data['commits'].keys()\n",
    "    for version in versions:\n",
    "        notebooks = data['commits'][version]['notebooks']\n",
    "        for notebook in notebooks:\n",
    "            info = notebook['analysis']\n",
    "            info['commit_id'] = version\n",
    "            info['notebook'] = notebook['name']\n",
    "            info['time'] = data['commits'][version]['time']\n",
    "            analysis.append(info)\n",
    "        \n",
    "    return analysis\n",
    "\n",
    "def convertToDate(isostr):\n",
    "    if (str(isostr) != 'nan'):\n",
    "        return parser.parse(isostr)\n",
    "\n",
    "def convertUnixTSToDate(unixstr):\n",
    "    return datetime.fromtimestamp(unixstr)\n",
    "\n",
    "def createDataFrame():\n",
    "\n",
    "    notebook_data = getNotebookData(data)\n",
    "    dfNb = pd.DataFrame.from_dict(notebook_data)\n",
    "    \n",
    "    cell_data = getCellData(data)\n",
    "    dfCell = pd.DataFrame.from_dict(cell_data)\n",
    "    dfCell['created-datetime'] = dfCell['created-datetime'].apply(convertToDate)\n",
    "    dfCell['time'] = dfCell['time'].apply(convertUnixTSToDate)\n",
    "    dfNb['time'] = dfNb['time'].apply(convertUnixTSToDate)\n",
    "    dfCell['deps_len'] = np.where(dfCell['deps'].str.len() > 0, dfCell['deps'].str.len(), 0)\n",
    "    dfCell['tags_len'] = np.where(dfCell['tags'].str.len() > 0, dfCell['tags'].str.len(), 0)\n",
    "    dfCell['vars_len'] = np.where(dfCell['vars'].str.len() > 0, dfCell['vars'].str.len(), 0)\n",
    "    dfCell['api_len'] = np.where(dfCell['api_calls'].str.len() > 0, dfCell['api_calls'].str.len(), 0)\n",
    "    dfCell['func_len'] = np.where(dfCell['func_definitions'].str.len() > 0, dfCell['func_definitions'].str.len(), 0)\n",
    "    dfCell['output_len'] = np.where(dfCell['outputs'].str.len() > 0, dfCell['outputs'].str.len(), 0)\n",
    "\n",
    "    # dfCell.to_csv('cell_data.csv')\n",
    "    # dfNb.to_csv('notebook_data.csv')\n",
    "    \n",
    "    return (dfCell, dfNb)\n",
    "\n",
    "data = getData()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deps": [],
    "tags": []
   },
   "source": [
    "### dfCell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deps": [],
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "The dfCell dataframe identifies every version of every cell in the analysis notebook. \n",
    "Each row in this dataframe corresponds to a single version of a single cell found in the analysis notebook. \n",
    "\n",
    "The dfCell dataframe has 31 attributes. They are:\n",
    "\n",
    "| Attribute Number | Attribute Name | Definition |\n",
    "| --- | --- | --- |\n",
    "| 0 | execution_count | This metric is generated by the Jupyter platform to designate both the number of times a cell has been executed and the order in which it appears next to other executed cells. |\n",
    "| 1 | id | This is a GUID generated by Cynosure to identify unique cells irrespective of the type of cell created. |\n",
    "| 2 | cell_type | Identifies the type of cell created. Can be \"markdown\", \"code\", \"raw\" |\n",
    "| 3 | source | The contents of the cell. Each line (ending with a new line character) is an item in this list. |\n",
    "| 4 | source_length | The number of \"lines\" found in the cell contents. |\n",
    "| 5 | outputs | The output contents as stored by the Jupyter platform. |\n",
    "| 6 | hash | A hash of the cell contents to enable comparison between cells. |\n",
    "| 7 | comments | The list of individual comments found in each cell. |\n",
    "| 8 | ln_comment_count | The number of single line comments made using the '#' character. |\n",
    "| 9 | multiln_comment_count | The number of multi-line comments made using the ''' characters. |\n",
    "| 10 | vars | A list of code variables defined in the cell found using the Python AST library. |\n",
    "| 11 | api_calls | A list of api calls found in the cell using regular expressions. |\n",
    "| 12 | func_definitions | A list of python function definitions found in the cell using Python AST. |\n",
    "| 13 | created-datetime | The date-time when the cell was created. |\n",
    "| 14 | deps | The other cell on which this cell is dependent upon. |\n",
    "| 15 | executions | The number of times the cell was cumulatively executed by the author. |\n",
    "| 16 | keystrokes | The number of times the cell was cumulatively edited by the author. |\n",
    "| 17 | modified-datetime | The date-time when the cell was last edited. |\n",
    "| 18 | tags | The tags associated with the cell. |\n",
    "| 19 | cell_index | The unique alpha numeric character associated with the cell. |\n",
    "| 20 | notebook | The name of the notebook in which the cell was found. |\n",
    "| 21 | commit_id | The unique id associated with a version of the cell. |\n",
    "| 22 | time | The date-time when the cell version was saved. |\n",
    "| 23 | metadata | The original dictionary structure of the meta-data associated with the cell. |\n",
    "| 24 | collapsed | A boolean showing whether the author collapsed the cell from being seen. |\n",
    "| 25 | jupyter | The version of jupyter used to edit this cell. |\n",
    "| 26 | deps_len | The number of dependencies of this cell. |\n",
    "| 27 | tags_len | The number of tags associated with this cell. |\n",
    "| 28 | vars_len | The number of variables in this cell. |\n",
    "| 29 | api_len | The number of api calls found in this cell. |\n",
    "| 30 | func_len | The number of function definitions found in this cell. |\n",
    "| 31 | output_len | The number of outputs from this cell. |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deps": [],
    "tags": []
   },
   "source": [
    "### dfNb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deps": [],
    "tags": []
   },
   "source": [
    "The dfNb dataframe identifies every version of the analysis notebook. \n",
    "Each row in this dataframe corresponds to a single version of the notebook found in the project directory. \n",
    "\n",
    "| Attribute Number | Attribute Name | Definition |\n",
    "| --- | --- | --- |\n",
    "| 0 | lang | The language the notebook was implemented in. |\n",
    "| 1 | avg_markdown_lang | The natural language (e.g. english, spanish, japanese) detected across cells in the notebook. |\n",
    "| 2 | ds_api_calls | A list of all API calls associated with common Data Science libraries. |\n",
    "| 3 | api_calls | A list of all API calls found in the notebook. |\n",
    "| 4 | libraries | A list of all data science Libraries (imports) found in the notebook. |\n",
    "| 5 | ast_connection | A score prescribed by Python AST of the relationship between code cells. | \n",
    "| 6 | all_libs | A list of all libraries (imports) found in the notebook.\n",
    "| 7 | date | The day when the notebook version was created. |\n",
    "| 8 | hashes | A list of hashes of the notebook cells to make it easy to compare cells. |\n",
    "| 9 | exec_order | A list of execution counts of notebook cells. |\n",
    "| 10 | exec_gap | The gap in the execution counts in notebook cell, used to indicate a break in the linearity of execution. |\n",
    "| 11 | no_exec_cells | Number of cells with no execution counts. |\n",
    "| 12 | exec_max | The maximum execution count. |\n",
    "| 13 | exec_min | The minimum execution count. |\n",
    "| 14 | code_count | The ratio of lines found in code cells (with output) to total lines in the notebook. |\n",
    "| 15 | text_count | The ratio of lines found in markdown cells to total lines in the notebook. |\n",
    "| 16 | raw_count | The ratio of lines found in raw cells to total lines in the notebook. |\n",
    "| 17 | noout_count | The ratio of lines found in code cells (without output) to total lines in the notebook. |\n",
    "| 18 | text_headers | The number of text headers. |\n",
    "| 19 | code_lines | The number of lines of code found in code cells. |\n",
    "| 20 | text_lines | The number of lines of markdown found in markdown cells. |\n",
    "| 21 | raw_lines | The number of lines found in raw cells. |\n",
    "| 22 | noout_lines | The number of lines found in code cells with no output. |\n",
    "| 23 | c_tot_lines | The number of lines found in the notebook excluding cells without execution history. |\n",
    "| 24 | tot_lines | Total number of lines of code or text across all cells. |\n",
    "| 25 | comment_count | The total number of independent comments within code cells. |\n",
    "| 26 | comment_lines | The total number of lines of comments within code cells. |\n",
    "| 27 | media_count | The total number of output. |\n",
    "| 28 | media_text | The total number of text output. |\n",
    "| 29 | media_image | The total number of image output. |\n",
    "| 30 | media_table | The total number of table output. |\n",
    "| 31 | media_error | The total number of output errors. |\n",
    "| 32 | avg_media_text | The ratio of code output that displayed text to all output. |\n",
    "| 33 | avg_media_image | The ratio of code output that displayed images to all output. |\n",
    "| 34 | avg_media_table | The ratio of code output that displayed a table to all output. |\n",
    "| 35 | avg_media_error | The ratio of code output that resulted in an error to all output. |\n",
    "| 36 | c_code_count | The ratio of code cell with output to total cells. |\n",
    "| 37 | c_text_count | The ratio of markdown cells with no output to total cells. |\n",
    "| 38 | c_noout_count | The ratio of code cells with no output to total cells. |\n",
    "| 39 | c_raw_count | The ratio of raw cells to total cells. |\n",
    "| 40 | tot_count | The total number of cells, excluding the cells with no execution history. |\n",
    "| 41 | code_cells | The total number of code cells that did have an output. |\n",
    "| 42 | text_cells | The total number of markdown cells. |\n",
    "| 43 | noout_cells | The total number of code cells that did not have an output. |\n",
    "| 44 | raw_cells | The total number of raw cells. |\n",
    "| 45 | tot_cells | The total number of cells. |\n",
    "| 46 | code_space | The number of space characters in code cells that did have an output. |\n",
    "| 47 | text_space | The number of space characters in markdown cells in the notebook. |\n",
    "| 48 | raw_space | The number of space characters in raw cells in the notebook. |\n",
    "| 49 | noout_space | The number of space characters in code cells that did not have an output. |\n",
    "| 50 | file_size | The file size of the notebook. |\n",
    "| 51 | commit_id | Version ID of the notebook. |\n",
    "| 52 | notebook | Name of the notebook. |\n",
    "| 53 | time | Time when the version was created. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfCell, dfNb = createDataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deps": [],
    "tags": []
   },
   "source": [
    "## Cell Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section focuses on analyzing and visualizing changes in cells within the notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolate cells with code\n",
    "tmp = dfCell[dfCell['cell_type'] == 'code'].dropna(subset=['executions', 'keystrokes'])\n",
    "tmp.set_index(['id', 'time', 'cell_index', 'commit_id'], inplace=True)\n",
    "tmp.sort_index(inplace=True)\n",
    "\n",
    "tmp['diffs_exec'] = np.nan\n",
    "tmp['diffs_ks'] = np.nan\n",
    "tmp['diffs_apis'] = np.nan\n",
    "\n",
    "# Determine the time frames/ commits when the number of executions\n",
    "# and the number of key strokes changed (when the author made and executed changes)\n",
    "\n",
    "# This process generates a warning because of the way in which we are slicing \n",
    "# the dataframe. (Ignore)\n",
    "dfCellCode = pd.DataFrame()\n",
    "for idx in tmp.index.levels[0]:\n",
    "    tmp.diffs_exec[idx] = tmp.executions[idx].diff()\n",
    "    tmp.diffs_ks[idx] = tmp.keystrokes[idx].diff()\n",
    "    tmp.diffs_apis[idx] = tmp.api_len[idx].diff()\n",
    "    \n",
    "# populate a new dataframe with this information\n",
    "dfCellCode['executions'] = tmp['diffs_exec']\n",
    "dfCellCode['keystrokes'] = tmp['diffs_ks']\n",
    "dfCellCode['apis'] = tmp['diffs_apis']\n",
    "\n",
    "dfCellCode['dependencies'] = tmp['deps_len']\n",
    "dfCellCode['tags'] = tmp['tags_len']\n",
    "dfCellCode['variables'] = tmp['vars_len']\n",
    "dfCellCode['functions'] = tmp['func_len']\n",
    "dfCellCode['outputs'] = tmp['output_len']\n",
    "\n",
    "# drop rows where executions and keystrokes were not defined\n",
    "dfCellCode = dfCellCode.dropna(subset=['executions', 'keystrokes'])\n",
    "\n",
    "# create another dataframe where we only look at non-zero execution or keystrokes\n",
    "dfCellCode_active = dfCellCode[(dfCellCode['executions'] > 0) | (dfCellCode['keystrokes'] > 0)]\n",
    "\n",
    "# save to file (optional)\n",
    "# dfCellCode.to_csv('code_cell_diff_data.csv')\n",
    "# dfCellCode_active.to_csv('code_cell_diff_data_active.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine time-frame when author made the most changes to code in terms of executing them, and editing them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(dfCellCode_active.reset_index(), title='Time frame when author executed code cells.').mark_point().encode(\n",
    "    x=alt.X('time:T', axis=alt.Axis(labelAngle=0)),\n",
    "    y='executions:Q',\n",
    "    color='cell_index:N'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(dfCellCode_active.reset_index(), title='Time frame when author made changes to code cells.').mark_point().encode(\n",
    "    x=alt.X('time:T', axis=alt.Axis(labelAngle=0)),\n",
    "    y='keystrokes:Q',\n",
    "    color='cell_index:N'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(dfCellCode_active.reset_index(), title='Time frame when author added API calls to code cells.').mark_point().encode(\n",
    "    x=alt.X('time:T', axis=alt.Axis(labelAngle=0)),\n",
    "    y='apis:Q',\n",
    "    color='cell_index:N'\n",
    ")\n",
    "\n",
    "#Note: Negative changes in the APIs indicate that the author was removing API calls from the cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(dfCellCode_active.reset_index(), title='Time frame when author executed code cells after making changes to them.').mark_circle().encode(\n",
    "    x=alt.X('time:T', axis=alt.Axis(labelAngle=0)),\n",
    "    y='executions:Q',\n",
    "    size='keystrokes:Q',\n",
    "    color='cell_index:N'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine the code cells which the authors grouped together in execution and in editing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(dfCellCode.reset_index(), title='Cells that are executed together within each time frame.').mark_rect().encode(\n",
    "    x='time:O',\n",
    "    y='cell_index:O',\n",
    "    color='executions:Q'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(dfCellCode.reset_index(), title='Cells that are edited together within each time frame.').mark_rect().encode(\n",
    "    x='time:O',\n",
    "    y='cell_index:O',\n",
    "    color='keystrokes:Q'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(dfCellCode.reset_index(), title='Changes in the number of API calls in code cells within each time frame.').mark_rect().encode(\n",
    "    x='time:O',\n",
    "    y='cell_index:O',\n",
    "    color='apis:Q'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine the life-span of cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simpler dataframe with start and end times of the cell's life-span\n",
    "# Find all unique cell IDs\n",
    "unique_cell_id = dfCell.id.unique()\n",
    "cell_duration = []\n",
    "\n",
    "# Iterate through each cell\n",
    "for id in unique_cell_id:\n",
    "    duration = {}\n",
    "    duration['id'] = id\n",
    "    cell = dfCell[dfCell['id'] == id]\n",
    "    cell_index = np.array(cell['cell_index'].unique())\n",
    "    times = np.array(cell['time'])\n",
    "    \n",
    "    # assign the start and end duration of cell\n",
    "    # cells will recieve the last time-stamp in \n",
    "    # which they continue to exist.\n",
    "    duration['type'] = np.array(cell['cell_type'].unique())[0]\n",
    "    duration['start'] = times[0]\n",
    "    duration['end'] = times[-1]\n",
    "    duration['cell_index'] = cell_index[0]\n",
    "    cell_duration.append(duration)\n",
    "\n",
    "cd = pd.DataFrame(cell_duration)\n",
    "cd = cd.sort_values(by = 'cell_index')\n",
    "cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(cd, title='Life span of each cell. Colors indicate code type.').mark_bar().encode(\n",
    "    x='start',\n",
    "    x2='end',\n",
    "    y='cell_index',\n",
    "    color='type'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simpler dataframe with start and end times of the cell's life-span\n",
    "# Find all unique cell IDs\n",
    "unique_cell_id = dfCell.id.unique()\n",
    "cell_duration = []\n",
    "\n",
    "# Iterate through each cell\n",
    "for id in unique_cell_id:\n",
    "    duration = {}\n",
    "    duration['id'] = id\n",
    "    cell = dfCell[dfCell['id'] == id]\n",
    "    cell_index = np.array(cell['cell_index'].unique())\n",
    "    times = np.array(cell['time'])\n",
    "    \n",
    "    # we will define life span of a cell based on when it was created\n",
    "    # and the last time it was modified.\n",
    "    createdtime = np.array(cell['created-datetime'])\n",
    "    modifiedtime = np.array(cell['modified-datetime'])\n",
    "    \n",
    "    # assign the start and end duration of cell\n",
    "    # cells will recieve the last time-stamp in \n",
    "    # which they continue to exist.\n",
    "    duration['type'] = np.array(cell['cell_type'].unique())[0]\n",
    "    duration['start'] = createdtime[0]\n",
    "    duration['end'] = modifiedtime[-1]\n",
    "    duration['cell_index'] = cell_index[0]\n",
    "    cell_duration.append(duration)\n",
    "\n",
    "cd = pd.DataFrame(cell_duration)\n",
    "cd = cd.sort_values(by = 'cell_index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(cd, title='Life span of each cell based on when they are created and last-modified.').mark_bar().encode(\n",
    "    x='start',\n",
    "    x2='end',\n",
    "    y='cell_index',\n",
    "    color='type'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine the life-span variables and APIs defined by the author. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_vars = []\n",
    "flat_apis = []\n",
    "\n",
    "# For each cell \n",
    "for id in unique_cell_id:\n",
    "    cell = dfCell[dfCell['id'] == id]\n",
    "    cell_index = (np.array(cell['cell_index'].unique()))[0]\n",
    "    var = np.array(cell['vars'])\n",
    "    api_calls = np.array(cell['api_calls'])\n",
    "    cids = np.array(cell['commit_id'])\n",
    "    times = np.array(cell['modified-datetime'])\n",
    "\n",
    "    # For each variable found in each cell (skips if cell is markdown) \n",
    "    for i, x in enumerate(var):\n",
    "        if (type(x) == list):\n",
    "            for vx in x:\n",
    "                v = {}\n",
    "                v['id'] = id\n",
    "                v['cell_index'] = cell_index\n",
    "                v['var'] = vx \n",
    "                v['commit_id'] = cids[i]\n",
    "                v['time'] = times[i]\n",
    "                flat_vars.append(v)\n",
    "\n",
    "    # For each api call found in each cell (skips if cell is markdown)\n",
    "    for j, x in enumerate(api_calls):\n",
    "        if (type(x) == list):\n",
    "            for ax in x:\n",
    "                a = {}\n",
    "                a['id'] = id\n",
    "                a['cell_index'] = cell_index\n",
    "                a['api'] = ax\n",
    "                a['commit_id'] = cids[j]\n",
    "                a['time'] = times[j]\n",
    "                flat_apis.append(a)\n",
    "\n",
    "\n",
    "flv = pd.DataFrame(flat_vars)\n",
    "\n",
    "vars = np.array(flv['var'].unique())\n",
    "var_life_span = []\n",
    "\n",
    "# For each variable\n",
    "# construct a life span dataframe\n",
    "for v in vars:\n",
    "    ls = {}\n",
    "    ls['var'] = v\n",
    "\n",
    "    for_var = flv[flv['var'] == v]\n",
    "    times = np.array(for_var['time'])\n",
    "    cell_index = np.array(for_var['cell_index'])[0]\n",
    "\n",
    "    ls['cell_index'] = cell_index\n",
    "    ls['start_time'] = times[0]\n",
    "    ls['end_time'] = times[-1]\n",
    "    var_life_span.append(ls)\n",
    "\n",
    "fla = pd.DataFrame(flat_apis)\n",
    "\n",
    "apis = np.array(fla['api'].unique())\n",
    "api_life_span = []\n",
    "\n",
    "# For each APIs\n",
    "# construct a life-span dataframe\n",
    "for v in apis:\n",
    "    ls = {}\n",
    "    ls['api'] = v\n",
    "\n",
    "    for_api = fla[fla['api'] == v]\n",
    "    times = np.array(for_api['time'])\n",
    "    cell_index = np.array(for_api['cell_index'])[0]\n",
    "\n",
    "    ls['cell_index'] = cell_index\n",
    "    ls['start_time'] = times[0]\n",
    "    ls['end_time'] = times[-1]\n",
    "    api_life_span.append(ls)\n",
    "\n",
    "var_data_life_span = pd.DataFrame(var_life_span)\n",
    "api_data_life_span = pd.DataFrame(api_life_span)\n",
    "\n",
    "var_data_life_span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_data_life_span = api_data_life_span.sort_values(by='cell_index')\n",
    "alt.Chart(api_data_life_span, title='A rough measure of when the APIs were modified based on when respective cells were last modified time.').mark_bar().encode(\n",
    "    x='start_time:T',\n",
    "    x2='end_time:T',\n",
    "    y='api:N',\n",
    "    color='cell_index:N'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_data_life_span = var_data_life_span.sort_values(by='cell_index')\n",
    "alt.Chart(var_data_life_span, title='A rough measure of when the variables were modified based on when respective cells were last modified time.').mark_bar().encode(\n",
    "    x='start_time:T',\n",
    "    x2='end_time:T',\n",
    "    y='var:N',\n",
    "    color='cell_index:N'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deps": [],
    "tags": []
   },
   "source": [
    "## Notebook Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(dfNb, title='Time frame when author experienced the most errors.').mark_point().encode(\n",
    "    x='time:T',\n",
    "    y='media_count:Q',\n",
    "    size='media_text:Q'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell Dependency Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With Cynosure, authors can track the dependencies between cells. This is particularly important to track since notebooks do not provide a guide on the order of execution for cells. Visualizing dependencies can be an easy way to track authors' dead-end analytical steps/ techniques. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyvis import network as net\n",
    "import networkx as nx\n",
    "from ipywidgets import interact\n",
    "\n",
    "# Get the contents of the cell for a particular version\n",
    "def getSource(notebook, commit, cell_id):\n",
    "    \n",
    "    dfCommit = dfCell[dfCell['commit_id'] == commit]\n",
    "    cell = dfCommit[dfCommit['id'] == cell_id]\n",
    "    if (len(cell) > 0):\n",
    "        cell_index = (cell['cell_index']).iat[0]\n",
    "        source = ''.join(cell['source'].iat[0])\n",
    "        \n",
    "        return (source, cell_index)\n",
    "    \n",
    "    # error handling\n",
    "    return ('', cell_id)\n",
    "\n",
    "# show dependency graph of cells in the notebook\n",
    "commits = list(data['commits'].keys())\n",
    "nbs = list(data['notebook_cell_graphs'].keys())\n",
    "print('Use slider to select commit and notebook')\n",
    "@interact(index=(0, len(commits) - 1), nbIndex=(0, len(nbs) - 1))\n",
    "def showDependencyData(index, nbIndex):\n",
    "    commit = commits[index]\n",
    "    notebook = nbs[nbIndex]\n",
    "    print('commit id: ' + commit)\n",
    "    print('commit time: ' + convertUnixTSToDate(data['commits'][commit]['time']).strftime(\"%Y-%m-%d %H:%M\"))\n",
    "    print('notebook: ' + notebook)\n",
    "    \n",
    "    g = net.Network(notebook=True, height='800px', width='100%')\n",
    "    \n",
    "    # construct one node for every cell\n",
    "    edges = []\n",
    "    nodes = data['notebook_cell_graphs'][notebook]['nodes'].keys()\n",
    "    \n",
    "    node_rename = {}\n",
    "    node_color = []\n",
    "    node_names = []\n",
    "    node_titles = []\n",
    "    \n",
    "    # markdown cells are green, code cells are black\n",
    "    metadata_node_color = '#00ff1e'\n",
    "    code_node_color = '#162347'\n",
    "    for i, n in enumerate(nodes):\n",
    "        node = data['notebook_cell_graphs'][notebook]['nodes'][n]\n",
    "        \n",
    "        if (commit in node['commits']):\n",
    "            source, cell_index = getSource(notebook, commit, node['id'])\n",
    "            \n",
    "            if (str(cell_index) != 'None'):\n",
    "                node_rename[n] = cell_index\n",
    "                node_titles.append(source)\n",
    "                node_names.append(cell_index)\n",
    "\n",
    "                if (node['type'] == 'code'):\n",
    "                    node_color.append(code_node_color)\n",
    "                else:\n",
    "                    node_color.append(metadata_node_color)        \n",
    "    \n",
    "    # construct one edge for every cell to cell dependency\n",
    "    edges_raw = data['notebook_cell_graphs'][notebook]['edges'].keys()\n",
    "    node_ognames = list(node_rename.keys())\n",
    "    for e in edges_raw:\n",
    "        edge = data['notebook_cell_graphs'][notebook]['edges'][e]\n",
    "        source = edge['source']\n",
    "        target = edge['target']\n",
    "        if (commit in edge['commits'] and (source in node_ognames and target in node_ognames)):\n",
    "            edges.append((node_rename[source], node_rename[target]))\n",
    "\n",
    "    # add nodes and edges to pyvis\n",
    "    g.add_nodes(node_names, color=node_color, title=node_titles)\n",
    "    for e in edges:\n",
    "        g.add_edge(e[0], e[1], value=1)\n",
    "\n",
    "    return g.show('example.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
